---
title: eLife Innovation Sprint - appstract.pub 
url: 2018/05/18/eLife_Innovation_Sprint_-_appstract.pub_/
date: 2018-05-18T00:00:00Z
categories:
- hackathon
- elife
- mozilla
- open-science
- cool
- citizen-science
---

Last week the eLife innovation sprint happened in Cambridge.  It was done in collaboration with the Mozilla global sprint. I was able to participate for some of the event, and I’ll write up a bit more about the project I worked on later. There is a slide deck that summarises all of the projects from the two days: Slides of outputs from the sprint:
[eLifeSprint2018_introductions_people&projects - Google Slides](https://docs.google.com/presentation/d/1gvyoGW-__7k41KFN4PLhZtpapHNr-4IoeMTIXMiFHDs/edit#slide=id.g37b02a27cf_74_0).

Briefly, this was hands down one of the most productive two-day sprints that I’ve ever been involved in. 

There is something longer to be written about the role that events like this can play in moving research tools forward, moving open science forward and enabling and enthusing communities. There is something longer to be written about sustainability models for research software and hacks, as well as some thinking to be done about where might be best to direct efforts in the ecosystem (at least in my mind). I had been thinking about setting jump some of that context before writing about the sprint, but that would be a blocker to actually writing about the amazing things that came out of the event, so framing aside, let’s start looking at some of the things that got built in just two days. 

### Appstract.pub 

For today’s post I just want to mention the hack that I was most impressed by, this was [appstract.pub](https://appstract.pub/#/). The problem they wanted to address is that papers about clinical trials or medial interventions can have a lot of variability around the number of people that the paper is about. If you are looking to find information about an intervention that has statistical power it would be a huge help to be able to filter by number of subjects, but this information is not captured as metadata. 

In two days they built a platform that shows the users abstracts from medical papers, uses machine learning in the browser to highlight potential information about numbers of people involved in the trial, and asks the user to confirm. 

Apart from the technical brilliance of doing this in just two days the app they built is also engaging, delightful and fun to use. This is a fully fledged crowd sourcing platform now, and it runs amazingly well on a mobile device. I’ve been casually annotating papers in spare moments, it’s just a fantastic hack, huge props to that team - Anisha, Charlie, Peter, Jen, Sam G, Andreea and Nuno. 


